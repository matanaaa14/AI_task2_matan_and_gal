{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4IR+uhCxi9iYRr/RWPsNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matanaaa14/AI_task2_matan_and_gal/blob/main/Boltzmann_R-Max_QLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "class CellType:\n",
        "    EMPTY = 0\n",
        "    WALL = 1\n",
        "    REWARD = 2\n",
        "\n",
        "class Cell:\n",
        "    def __init__(self, reward=0, cell_type=CellType.EMPTY, step_cost=-1):\n",
        "        self.reward = reward\n",
        "        self.cell_type = cell_type\n",
        "        self.step_cost = step_cost\n",
        "\n",
        "    def get_reward(self):\n",
        "        return self.reward\n",
        "\n",
        "    def get_cell_type(self):\n",
        "        return self.cell_type\n",
        "\n",
        "    def get_step_cost(self):\n",
        "        return self.step_cost\n",
        "\n",
        "class Grid:\n",
        "    def __init__(self, height, width):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.grid = [[Cell() for _ in range(width)] for _ in range(height)]\n",
        "\n",
        "    def set_cell(self, row, col, reward=0, cell_type=CellType.EMPTY, step_cost=-1):\n",
        "        self.grid[row][col] = Cell(reward, cell_type, step_cost)\n",
        "\n",
        "    def get_cell(self, row, col):\n",
        "        return self.grid[row][col]\n",
        "\n",
        "    def get_height(self):\n",
        "        return self.height\n",
        "\n",
        "    def get_width(self):\n",
        "        return self.width\n",
        "\n",
        "class TransitionModel:\n",
        "    def __init__(self, grid):\n",
        "        self.grid = grid\n",
        "        self.transitions = {}\n",
        "\n",
        "    def record_transition(self, state, action, next_state):\n",
        "        state_key = (state[0], state[1])\n",
        "        action_key = action\n",
        "        next_state_key = (next_state[0], next_state[1])\n",
        "\n",
        "        if state_key not in self.transitions:\n",
        "            self.transitions[state_key] = {}\n",
        "        if action_key not in self.transitions[state_key]:\n",
        "            self.transitions[state_key][action_key] = {}\n",
        "        if next_state_key not in self.transitions[state_key][action_key]:\n",
        "            self.transitions[state_key][action_key][next_state_key] = 0\n",
        "\n",
        "        self.transitions[state_key][action_key][next_state_key] += 1\n",
        "\n",
        "    def get_transition_probability(self, state, action, next_state):\n",
        "        state_key = (state[0], state[1])\n",
        "        action_key = action\n",
        "        next_state_key = (next_state[0], next_state[1])\n",
        "\n",
        "        if state_key in self.transitions and action_key in self.transitions[state_key] and next_state_key in self.transitions[state_key][action_key]:\n",
        "            total_transitions = sum(self.transitions[state_key][action_key].values())\n",
        "            return self.transitions[state_key][action_key][next_state_key] / total_transitions\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "class PolicyIterationRMax:\n",
        "    def __init__(self, grid, transition_model, epsilon=0.01, max_iterations=1000):\n",
        "        self.grid = grid\n",
        "        self.transition_model = transition_model\n",
        "        self.utilities = np.zeros((grid.get_height(), grid.get_width()))\n",
        "        self.policy = np.full((grid.get_height(), grid.get_width()), None)\n",
        "        self.epsilon = epsilon\n",
        "        self.max_iterations = max_iterations\n",
        "        self.actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]  # Right, Left, Down, Up\n",
        "\n",
        "    def run(self):\n",
        "        width = self.grid.get_width()\n",
        "        height = self.grid.get_height()\n",
        "        new_utilities = np.zeros((height, width))\n",
        "\n",
        "        for _ in range(self.max_iterations):\n",
        "            delta = 0\n",
        "            for i in range(height):\n",
        "                for j in range(width):\n",
        "                    cell = self.grid.get_cell(i, j)\n",
        "                    reward = cell.get_reward()\n",
        "                    if cell.get_cell_type() == CellType.WALL:\n",
        "                        new_utilities[i, j] = 0\n",
        "                        self.policy[i, j] = None\n",
        "                    elif reward != 0:\n",
        "                        new_utilities[i, j] = reward\n",
        "                        self.policy[i, j] = None\n",
        "                    else:\n",
        "                        max_utility = float('-inf')\n",
        "                        best_action = None\n",
        "                        for action_idx, action in enumerate(self.actions):\n",
        "                            utility = 0\n",
        "                            for prob, delta_action in [(0.8, action), (0.1, (-action[0], action[1])), (0.1, (action[0], -action[1]))]:\n",
        "                                new_x = i + delta_action[0]\n",
        "                                new_y = j + delta_action[1]\n",
        "                                if 0 <= new_x < height and 0 <= new_y < width:\n",
        "                                    if self.grid.get_cell(new_x, new_y).get_cell_type() == CellType.WALL:\n",
        "                                        utility += prob * self.utilities[i, j]\n",
        "                                    else:\n",
        "                                        utility += prob * self.utilities[new_x, new_y]\n",
        "                                else:\n",
        "                                    utility += prob * self.utilities[i, j]\n",
        "                            if utility > max_utility:\n",
        "                                max_utility = utility\n",
        "                                best_action = action_idx\n",
        "                        new_utilities[i, j] = cell.get_step_cost() + max_utility\n",
        "                        self.policy[i, j] = best_action\n",
        "\n",
        "                        delta = max(delta, abs(new_utilities[i, j] - self.utilities[i, j]))\n",
        "\n",
        "            self.utilities = np.copy(new_utilities)\n",
        "\n",
        "            if delta < self.epsilon:\n",
        "                break\n",
        "\n",
        "            # Update transition model with observed transitions\n",
        "            self.update_transition_model()\n",
        "\n",
        "        return self.utilities\n",
        "\n",
        "    def update_transition_model(self):\n",
        "        for i in range(self.grid.get_height()):\n",
        "            for j in range(self.grid.get_width()):\n",
        "                if self.policy[i, j] is not None:\n",
        "                    action = self.policy[i, j]\n",
        "                    next_state = self.get_next_state([i, j], action)\n",
        "                    self.transition_model.record_transition([i, j], action, next_state)\n",
        "\n",
        "    def get_utilities(self):\n",
        "        return self.utilities\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self.policy\n",
        "\n",
        "    def evaluate_policy(self, episodes=1000):\n",
        "        total_return = 0\n",
        "        for _ in range(episodes):\n",
        "            state = [0, 0]\n",
        "            episode_return = 0\n",
        "            steps = 0\n",
        "            while self.grid.get_cell(state[0], state[1]).get_reward() == 0 and steps < 1000:\n",
        "                action = self.policy[state[0], state[1]]\n",
        "                next_state = self.get_next_state(state, action)\n",
        "                reward = self.grid.get_cell(next_state[0], next_state[1]).get_reward() + self.grid.get_cell(state[0], state[1]).get_step_cost()\n",
        "                episode_return += reward\n",
        "                state = next_state\n",
        "                steps += 1\n",
        "            total_return += episode_return\n",
        "        return total_return / episodes\n",
        "\n",
        "    def get_next_state(self, state, action_idx):\n",
        "        move = self.actions[action_idx]\n",
        "        next_state = [state[0] + move[0], state[1] + move[1]]\n",
        "        if not self.is_valid_location(next_state):\n",
        "            next_state = state\n",
        "        return next_state\n",
        "\n",
        "    def is_valid_location(self, location):\n",
        "        return (0 <= location[0] < self.grid.get_height() and\n",
        "                0 <= location[1] < self.grid.get_width() and\n",
        "                self.grid.get_cell(location[0], location[1]).get_cell_type() != CellType.WALL)\n",
        "\n",
        "    def print_policy(self):\n",
        "        direction_mapping = ['→', '←', '↓', '↑']\n",
        "        policy = [['' for _ in range(self.grid.get_width())] for _ in range(self.grid.get_height())]\n",
        "\n",
        "        for row in range(self.grid.get_height()):\n",
        "            for col in range(self.grid.get_width()):\n",
        "                cell = self.grid.get_cell(row, col)\n",
        "                if cell.get_cell_type() == CellType.WALL:\n",
        "                    policy[row][col] = 'W'  # Wall\n",
        "                elif cell.get_reward() > 0:\n",
        "                    policy[row][col] = 'P'  # Positive reward\n",
        "                elif cell.get_reward() < 0:\n",
        "                    policy[row][col] = 'N'  # Negative reward\n",
        "                else:\n",
        "                    best_action = self.policy[row, col]\n",
        "                    policy[row][col] = direction_mapping[best_action] if best_action is not None else ' '\n",
        "\n",
        "        # Print Policy\n",
        "        print(\"Policy:\")\n",
        "        for row in policy:\n",
        "            print(\" \".join(row))\n",
        "\n",
        "        # Print Utilities using tabulate for prettier printing\n",
        "        utilities_table = [[\"{:.5f}\".format(value) for value in row] for row in self.utilities]\n",
        "        print(\"\\nUtilities:\")\n",
        "        print(tabulate(utilities_table, tablefmt=\"fancy_grid\", numalign=\"center\", stralign=\"center\"))\n",
        "\n",
        "\n",
        "# Example usage with the grid setup\n",
        "def main_policy_iteration_rmax(w, h, L, p, r):\n",
        "    grid = Grid(h, w)\n",
        "\n",
        "    for x, y, value in L:\n",
        "        grid.set_cell(h - y - 1, x, reward=value, cell_type=CellType.REWARD if value != 0 else CellType.WALL)\n",
        "\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if grid.get_cell(i, j).get_cell_type() == CellType.EMPTY:\n",
        "                grid.set_cell(i, j, step_cost=r)\n",
        "\n",
        "    transition_model = TransitionModel(grid)\n",
        "    pir = PolicyIterationRMax(grid, transition_model)\n",
        "\n",
        "    start_time = time.time()\n",
        "    pir.run()\n",
        "    end_time = time.time()\n",
        "\n",
        "    policy_score = pir.evaluate_policy(episodes=1000)\n",
        "    print(\"Policy Score:\", policy_score)\n",
        "    print(f\"Policy Iteration R-max Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "    print(\"\\nPolicy:\")\n",
        "    pir.print_policy()\n",
        "    print(\"=======================================\")\n",
        "\n",
        "# Test each case\n",
        "test_cases = [\n",
        "    # Test case 1\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, -0.04),\n",
        "    # Test case 2\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, 0.04),\n",
        "    # Test case 3\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, -1),\n",
        "    # Test case 4\n",
        "    (12, 4, [(1,0,-100),(2,0,-100),(3,0,-100),(4,0,-100),(5,0,-100),(6,0,-100),(7,0,-100),(8,0,-100),(9,0,-100),(10,0,-100),(11,0,1)], 1, -1),\n",
        "    # Test case 5\n",
        "    (12, 6, [(1,0,-100),(2,0,-100),(3,0,-100),(4,0,-100),(5,0,-100),(6,0,-100),(7,0,-100),(8,0,-100),(9,0,-100),(10,0,-100),(11,0,1)], 0.9, -1),\n",
        "    # Test case 6\n",
        "    (5, 5, [(4,0,-10),(0,4,-10),(1,1,1),(3,3,2)], 0.9, -0.5),\n",
        "    # Test case 7\n",
        "    (5, 5, [(2,2,-2),(4,4,-1),(1,1,1),(3,3,2)], 0.9, -0.25),\n",
        "    # Test case 8\n",
        "    (7, 7, [(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.5),\n",
        "    # Test case 9\n",
        "    (7, 7, [(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.5),\n",
        "    # Test case 10\n",
        "    (7, 7, [(3,1,0),(3,5,0),(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.25)\n",
        "]\n",
        "\n",
        "for i, (w, h, L, p, r) in enumerate(test_cases, start=1):\n",
        "    print(f\"\\nRunning test case {i}\")\n",
        "    main_policy_iteration_rmax(w, h, L, p, r)\n"
      ],
      "metadata": {
        "id": "pwqVIgmGZEfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b3aced-c06d-4fe1-eb7f-c3a609ce102e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running test case 1\n",
            "Policy Score: 0.8799999999999959\n",
            "Policy Iteration R-max Time: 0.0059 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "→ → ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╕\n",
            "│ 0.85568 │ 0.90041 │ 0.95002 │    1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.80401 │    0    │ 0.90041 │   -1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.75641 │ 0.80401 │ 0.85568 │ 0.81011 │\n",
            "╘═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 2\n",
            "Policy Score: 39.999999999999844\n",
            "Policy Iteration R-max Time: 0.6046 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → ↓ P\n",
            "→ W ↓ N\n",
            "→ → → →\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╕\n",
            "│ 40.8556 │ 40.8556 │ 40.8556 │    1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 40.8556 │    0    │ 40.8556 │   -1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 40.8556 │ 40.8556 │ 40.8556 │ 40.8556 │\n",
            "╘═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 3\n",
            "Policy Score: -2.0\n",
            "Policy Iteration R-max Time: 0.0023 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "→ → ↑ ↑\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╕\n",
            "│ -2.5944  │ -1.48284 │ -0.24833 │    1     │\n",
            "├──────────┼──────────┼──────────┼──────────┤\n",
            "│ -3.8286  │    0     │ -1.48284 │    -1    │\n",
            "├──────────┼──────────┼──────────┼──────────┤\n",
            "│ -4.94287 │ -3.8286  │ -2.5944  │ -2.11111 │\n",
            "╘══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 4\n",
            "Policy Score: -13.0\n",
            "Policy Iteration R-max Time: 0.0180 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → → ↓ → ↓ ↓ → ↓ ↓\n",
            "→ → → → ↓ → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ N N N N N N N N N N P\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│ -16.1816 │ -15.0748 │ -13.8403 │ -12.5935 │ -11.3437 │ -10.0939 │ -8.84393 │ -7.59396 │ -6.34396 │ -5.09396 │ -3.84396 │ -2.59396 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -15.0748 │ -13.9633 │ -12.7306 │ -11.4822 │ -10.2328 │ -8.98279 │ -7.73285 │ -6.48285 │ -5.23285 │ -3.98285 │ -2.73285 │ -1.48285 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -13.8403 │ -12.7306 │ -11.4959 │ -10.248  │ -8.99818 │ -7.74828 │ -6.49828 │ -5.24829 │ -3.99828 │ -2.74829 │ -1.49829 │ -0.24829 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -14.9515 │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │    1     │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 5\n",
            "Policy Score: -15.0\n",
            "Policy Iteration R-max Time: 0.0313 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "↓ ↓ → → ↓ → ↓ → ↓ → ↓ ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → ↓ → → → → ↓ ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ N N N N N N N N N N P\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│ -18.6759 │ -17.5724 │ -16.3384 │ -15.0928 │ -13.8431 │ -12.5937 │ -11.3437 │ -10.0937 │ -8.84374 │ -7.59375 │ -6.34375 │ -5.09375 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -17.5724 │ -16.461  │  -15.23  │ -13.9815 │ -12.7325 │ -11.4825 │ -10.2326 │ -8.98262 │ -7.73264 │ -6.48264 │ -5.23264 │ -3.98264 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -16.3384 │  -15.23  │ -13.9951 │ -12.7477 │ -11.4979 │ -10.2481 │ -8.99805 │ -7.74807 │ -6.49807 │ -5.24807 │ -3.99807 │ -2.74807 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -15.0928 │ -13.9815 │ -12.7477 │ -11.4994 │ -10.2498 │ -8.99976 │ -7.74979 │ -6.49978 │ -5.24979 │ -3.99979 │ -2.74979 │ -1.49979 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -13.8431 │ -12.7325 │ -11.4979 │ -10.2498 │ -8.99992 │ -7.74998 │ -6.49997 │ -5.24998 │ -3.99998 │ -2.74998 │ -1.49998 │ -0.24998 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -14.9543 │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │    1     │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 6\n",
            "Policy Score: 0.0\n",
            "Policy Iteration R-max Time: 0.0035 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "N ↓ → ↓ ←\n",
            "→ → → P ←\n",
            "→ ↓ → ↑ ↑\n",
            "→ P ← ↑ ←\n",
            "→ ↑ ← ↑ N\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤═════════╤══════════╤═════════╤═════════╕\n",
            "│   -10    │ 0.19013 │ 0.81839  │ 1.44444 │ 0.88889 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ 0.19013  │ 0.75541 │ 1.37464  │    2    │ 1.44444 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ -0.08161 │ 0.47464 │ 0.78446  │ 1.37464 │ 0.81839 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ 0.44444  │    1    │ 0.47464  │ 0.75541 │ 0.19013 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ -0.11111 │ 0.44444 │ -0.08161 │ 0.19013 │   -10   │\n",
            "╘══════════╧═════════╧══════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 7\n",
            "Policy Score: 1.0\n",
            "Policy Iteration R-max Time: 0.0045 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → ↓ N\n",
            "→ → → P ←\n",
            "→ ↑ N ↑ ←\n",
            "→ P → ↑ ↑\n",
            "→ ↑ ↑ ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╤═════════╕\n",
            "│ 0.81784 │ 1.09867 │ 1.40967 │ 1.72222 │   -1    │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.09867 │ 1.37847 │ 1.68767 │    2    │ 1.72222 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.80925 │  1.089  │   -2    │ 1.68767 │ 1.40967 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.72222 │    1    │  1.089  │ 1.37847 │ 1.09867 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.44444 │ 0.72222 │ 0.80925 │ 1.09867 │ 0.81784 │\n",
            "╘═════════╧═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 8\n",
            "Policy Score: 1.0\n",
            "Policy Iteration R-max Time: 0.0316 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → → ↓ ←\n",
            "↑ N → → → P ←\n",
            "→ → → → → ↑ ↑\n",
            "→ → → ↑ ↑ ↑ ↑\n",
            "→ → → → ↑ ↑ ↑\n",
            "↑ N ↑ ↑ ↑ P ↑\n",
            "→ → → → ↑ ↑ ↑\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤═════════╤═════════╤═════════╤═════════╕\n",
            "│ 0.39738  │ 0.95305  │ 1.57037  │ 2.19454 │ 2.81945 │ 3.44444 │ 2.88889 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -0.10974 │    -6    │ 1.29268  │ 2.65854 │ 3.36585 │    4    │ 3.44444 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.32723  │ 0.88298  │  1.5003  │ 2.12449 │ 2.7494  │ 3.37439 │ 2.81945 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│  -0.298  │ 0.25772  │ 0.87535  │ 1.49954 │ 2.12449 │ 2.7439  │ 2.19455 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -0.92358 │ -0.36667 │ 0.25085  │ 0.87536 │ 1.50031 │ 2.06951 │ 1.57039 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -1.5422  │    -4    │ -0.36665 │ 0.25777 │  0.883  │    1    │ 0.95309 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -2.10226 │ -1.54203 │ -0.92346 │ -0.2979 │ 0.32729 │ 0.44444 │ 0.39747 │\n",
            "╘══════════╧══════════╧══════════╧═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 9\n",
            "Policy Score: 1.0\n",
            "Policy Iteration R-max Time: 0.0174 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → → ↓ ←\n",
            "↑ N → → → P ←\n",
            "→ → → → → ↑ ↑\n",
            "→ → → ↑ ↑ ↑ ↑\n",
            "→ → → → ↑ ↑ ↑\n",
            "↑ N ↑ ↑ ↑ P ↑\n",
            "→ → → → ↑ ↑ ↑\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤═════════╤═════════╤═════════╤═════════╕\n",
            "│ 0.39738  │ 0.95305  │ 1.57037  │ 2.19454 │ 2.81945 │ 3.44444 │ 2.88889 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -0.10974 │    -6    │ 1.29268  │ 2.65854 │ 3.36585 │    4    │ 3.44444 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.32723  │ 0.88298  │  1.5003  │ 2.12449 │ 2.7494  │ 3.37439 │ 2.81945 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│  -0.298  │ 0.25772  │ 0.87535  │ 1.49954 │ 2.12449 │ 2.7439  │ 2.19455 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -0.92358 │ -0.36667 │ 0.25085  │ 0.87536 │ 1.50031 │ 2.06951 │ 1.57039 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -1.5422  │    -4    │ -0.36665 │ 0.25777 │  0.883  │    1    │ 0.95309 │\n",
            "├──────────┼──────────┼──────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ -2.10226 │ -1.54203 │ -0.92346 │ -0.2979 │ 0.32729 │ 0.44444 │ 0.39747 │\n",
            "╘══════════╧══════════╧══════════╧═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 10\n",
            "Policy Score: 2.5\n",
            "Policy Iteration R-max Time: 0.0170 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → ↓ ↓ ←\n",
            "↑ N ↑ W → P ←\n",
            "→ → → → ↑ ↑ ↑\n",
            "→ → → ↑ ↑ ↑ ↑\n",
            "→ → → ↑ ↑ ↑ ↑\n",
            "↑ N ↑ W ↑ P ↑\n",
            "→ → ↑ → ↑ → ↑\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
            "│ 2.23336 │ 2.51121 │ 2.8199  │ 3.13199 │ 3.44444 │ 3.72222 │ 3.44444 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.97969 │   -6    │ 2.5664  │    0    │ 3.72222 │    4    │ 3.72222 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 2.1985  │ 2.4764  │ 2.78516 │ 3.09726 │ 3.40973 │ 3.68537 │ 3.40973 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.88922 │ 2.16756 │ 2.4764  │ 2.7886  │ 3.09726 │ 3.35366 │ 3.09726 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.61069 │ 1.88923 │ 2.19851 │ 2.51077 │ 2.78517 │ 2.86829 │ 2.78517 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.29865 │   -4    │ 1.88923 │    0    │ 2.47643 │    1    │ 2.47643 │\n",
            "├─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.01639 │ 1.29865 │ 1.61069 │ 1.88933 │ 2.19855 │ 1.94828 │ 2.19856 │\n",
            "╘═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLNFmm2UFFND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d3bcd3-53c5-4220-afa5-8cf1f1bc7c78",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running test case 1\n",
            "Policy Score: 0.8799999999999959\n",
            "Policy Iteration Boltzmann Time: 0.0044 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "↑ → ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╕\n",
            "│ 0.44903 │ 0.58588 │ 0.76902 │    1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.32858 │    0    │ 0.58588 │   -1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 0.23768 │ 0.32858 │ 0.44903 │ 0.33694 │\n",
            "╘═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 2\n",
            "Policy Score: 39.999999999999844\n",
            "Policy Iteration Boltzmann Time: 0.0018 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ ↓ ↑ P\n",
            "↑ W ↑ N\n",
            "↑ → ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒═════════╤═════════╤═════════╤═════════╕\n",
            "│ 1.04005 │ 1.04006 │ 1.04001 │    1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.03791 │    0    │ 1.03994 │   -1    │\n",
            "├─────────┼─────────┼─────────┼─────────┤\n",
            "│ 1.03367 │ 1.03724 │ 1.03991 │ 1.03909 │\n",
            "╘═════════╧═════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 3\n",
            "Policy Score: -2.0\n",
            "Policy Iteration Boltzmann Time: 0.0162 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "→ → ↑ ↑\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╕\n",
            "│ -1.7764  │ -1.38308 │ -0.58475 │    1     │\n",
            "├──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.9888  │    0     │ -1.38308 │    -1    │\n",
            "├──────────┼──────────┼──────────┼──────────┤\n",
            "│ -2.09456 │ -1.9888  │ -1.7764  │ -1.57687 │\n",
            "╘══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 4\n",
            "Policy Score: -13.0\n",
            "Policy Iteration Boltzmann Time: 0.0855 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → ↓ ↓ → → → → → → → ↓\n",
            "→ → → ↓ → → → → → ↓ ↓ ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ N N N N N N N N N N P\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│ -1.9829  │ -1.98281 │ -1.98263 │ -1.98225 │ -1.98146 │ -1.97979 │ -1.97629 │ -1.96887 │ -1.95304 │ -1.91911 │ -1.84595 │ -1.68735 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.98281 │ -1.98264 │ -1.98227 │ -1.9815  │ -1.97988 │ -1.97648 │ -1.96926 │ -1.95387 │ -1.92087 │ -1.84972 │ -1.69548 │ -1.35926 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.98263 │ -1.98227 │ -1.9815  │ -1.97989 │ -1.97648 │ -1.96927 │ -1.95389 │ -1.92091 │ -1.84981 │ -1.69568 │ -1.35968 │ -0.62319 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.9828  │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │    1     │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 5\n",
            "Policy Score: -15.0\n",
            "Policy Iteration Boltzmann Time: 0.1396 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ ↓ ↓ → ↓ → ↓ ↓ ↓ → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ ↓ → → → → → ↓ ↓ → ↓ ↓\n",
            "→ → → → ↓ → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ N N N N N N N N N N P\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│ -1.98296 │ -1.98294 │ -1.9829  │ -1.98281 │ -1.98263 │ -1.98225 │ -1.98146 │ -1.97979 │ -1.97629 │ -1.96887 │ -1.95304 │ -1.91911 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.98294 │ -1.9829  │ -1.98281 │ -1.98264 │ -1.98227 │ -1.9815  │ -1.97988 │ -1.97648 │ -1.96926 │ -1.95387 │ -1.92087 │ -1.84972 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.9829  │ -1.98281 │ -1.98264 │ -1.98227 │ -1.9815  │ -1.97989 │ -1.97648 │ -1.96927 │ -1.95389 │ -1.92091 │ -1.84981 │ -1.69568 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.98281 │ -1.98264 │ -1.98227 │ -1.9815  │ -1.97989 │ -1.97648 │ -1.96927 │ -1.95389 │ -1.92091 │ -1.84982 │ -1.69568 │ -1.35969 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.98263 │ -1.98227 │ -1.9815  │ -1.97989 │ -1.97648 │ -1.96927 │ -1.95389 │ -1.92091 │ -1.84982 │ -1.69568 │ -1.35969 │ -0.62321 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -1.9828  │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │   -100   │    1     │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 6\n",
            "Policy Score: 0.0\n",
            "Policy Iteration Boltzmann Time: 0.0218 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "N ↓ ↓ ↓ ←\n",
            "→ → → P ←\n",
            "↓ ↓ → ↑ ←\n",
            "→ P ← ↑ ←\n",
            "→ ↑ ← ↑ N\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤═════════╤══════════╤═════════╤═════════╕\n",
            "│   -10    │ -0.4595 │  0.1464  │ 0.96967 │ 0.19749 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ -0.4595  │ 0.0993  │ 0.90235  │    2    │ 0.96967 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ -0.38327 │ 0.20537 │ 0.15056  │ 0.90235 │ 0.1464  │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ 0.21384  │    1    │ 0.20537  │ 0.0993  │ -0.4595 │\n",
            "├──────────┼─────────┼──────────┼─────────┼─────────┤\n",
            "│ -0.37717 │ 0.21384 │ -0.38327 │ -0.4595 │   -10   │\n",
            "╘══════════╧═════════╧══════════╧═════════╧═════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 7\n",
            "Policy Score: 1.0\n",
            "Policy Iteration Boltzmann Time: 0.0244 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ ↓ → ↓ N\n",
            "→ → → P ←\n",
            "→ ↓ N ↑ ↑\n",
            "→ P ← ↑ ←\n",
            "→ ↑ ↑ ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤═════════╤═════════╤═════════╤══════════╕\n",
            "│ -0.18051 │ 0.11385 │ 0.55267 │ 1.17733 │    -1    │\n",
            "├──────────┼─────────┼─────────┼─────────┼──────────┤\n",
            "│ 0.11385  │ 0.51996 │ 1.12858 │    2    │ 1.17733  │\n",
            "├──────────┼─────────┼─────────┼─────────┼──────────┤\n",
            "│ 0.06545  │ 0.45899 │   -2    │ 1.12858 │ 0.55267  │\n",
            "├──────────┼─────────┼─────────┼─────────┼──────────┤\n",
            "│ 0.45362  │    1    │ 0.45899 │ 0.51996 │ 0.11385  │\n",
            "├──────────┼─────────┼─────────┼─────────┼──────────┤\n",
            "│ 0.06118  │ 0.45362 │ 0.06545 │ 0.11385 │ -0.18051 │\n",
            "╘══════════╧═════════╧═════════╧═════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 8\n",
            "Policy Score: 1.0\n",
            "Policy Iteration Boltzmann Time: 0.0910 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → → ↓ ←\n",
            "↑ N → → → P ←\n",
            "→ → → → → ↑ ←\n",
            "→ → → → ↑ ↑ ↑\n",
            "→ → → → → ↓ ↓\n",
            "↑ N ↑ → → P ←\n",
            "→ → → → → ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│  -0.954  │ -0.89405 │ -0.76395 │ -0.48692 │ 0.10594  │ 1.38164  │ 0.13759  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98185 │    -6    │ -0.77093 │  0.0612  │ 1.31505  │    4     │ 1.38164  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.95556 │ -0.89724 │ -0.77066 │ -0.50112 │ 0.07572  │ 1.31696  │ 0.10652  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98427 │  -0.956  │ -0.89495 │ -0.76564 │ -0.49038 │  0.0988  │ -0.4756  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98817 │ -0.96372 │ -0.91078 │ -0.79826 │ -0.55792 │ -0.04175 │ -0.54507 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.99952 │    -4    │ -0.9598  │ -0.5821  │ -0.07637 │    1     │ -0.04947 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98839 │ -0.96416 │ -0.91167 │ -0.80007 │ -0.56165 │ -0.04947 │ -0.5489  │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 9\n",
            "Policy Score: 1.0\n",
            "Policy Iteration Boltzmann Time: 0.0999 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → → ↓ ←\n",
            "↑ N → → → P ←\n",
            "→ → → → → ↑ ←\n",
            "→ → → → ↑ ↑ ↑\n",
            "→ → → → → ↓ ↓\n",
            "↑ N ↑ → → P ←\n",
            "→ → → → → ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
            "│  -0.954  │ -0.89405 │ -0.76395 │ -0.48692 │ 0.10594  │ 1.38164  │ 0.13759  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98185 │    -6    │ -0.77093 │  0.0612  │ 1.31505  │    4     │ 1.38164  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.95556 │ -0.89724 │ -0.77066 │ -0.50112 │ 0.07572  │ 1.31696  │ 0.10652  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98427 │  -0.956  │ -0.89495 │ -0.76564 │ -0.49038 │  0.0988  │ -0.4756  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98817 │ -0.96372 │ -0.91078 │ -0.79826 │ -0.55792 │ -0.04175 │ -0.54507 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.99952 │    -4    │ -0.9598  │ -0.5821  │ -0.07637 │    1     │ -0.04947 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
            "│ -0.98839 │ -0.96416 │ -0.91167 │ -0.80007 │ -0.56165 │ -0.04947 │ -0.5489  │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
            "=======================================\n",
            "\n",
            "Running test case 10\n",
            "Policy Score: 2.5\n",
            "Policy Iteration Boltzmann Time: 0.0931 seconds\n",
            "\n",
            "Policy:\n",
            "Policy:\n",
            "→ → → → ↓ ↓ ←\n",
            "↑ N ↑ W → P ←\n",
            "→ → → → ↑ ↑ ←\n",
            "↑ → ↑ ↑ ↑ ↑ ↑\n",
            "→ → → → ↓ ↓ ←\n",
            "↑ N ↑ W → P ←\n",
            "→ → → → ↑ ↑ ←\n",
            "\n",
            "Utilities:\n",
            "╒══════════╤══════════╤══════════╤══════════╤══════════╤═════════╤══════════╕\n",
            "│ -0.45169 │ -0.39758 │ -0.27951 │ -0.02664 │ 0.51761  │ 1.63491 │ 0.51761  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.47669 │    -6    │ -0.38911 │    0     │ 1.63491  │    4    │ 1.63491  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.4531  │ -0.40046 │ -0.2856  │ -0.03961 │ 0.48985  │ 1.57681 │ 0.48985  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.47903 │ -0.45383 │ -0.39913 │ -0.28259 │ -0.03309 │ 0.47629 │ -0.03309 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.48559 │ -0.46707 │ -0.42672 │ -0.34045 │ -0.15506 │ 0.2249  │ -0.15506 │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.49416 │    -4    │ -0.46414 │    0     │ 0.21134  │    1    │ 0.21134  │\n",
            "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
            "│ -0.48596 │ -0.4678  │ -0.42824 │ -0.3436  │ -0.16167 │ 0.21134 │ -0.16167 │\n",
            "╘══════════╧══════════╧══════════╧══════════╧══════════╧═════════╧══════════╛\n",
            "=======================================\n"
          ]
        }
      ],
      "source": [
        "#-----------------\n",
        "#Model base -RL (boltzmann)\n",
        "#-----------------\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "class CellType:\n",
        "    EMPTY = 0\n",
        "    WALL = 1\n",
        "    REWARD = 2\n",
        "\n",
        "class Cell:\n",
        "    def __init__(self, reward=0, cell_type=CellType.EMPTY, step_cost=-1):\n",
        "        self.reward = reward\n",
        "        self.cell_type = cell_type\n",
        "        self.step_cost = step_cost\n",
        "\n",
        "    def get_reward(self):\n",
        "        return self.reward\n",
        "\n",
        "    def get_cell_type(self):\n",
        "        return self.cell_type\n",
        "\n",
        "    def get_step_cost(self):\n",
        "        return self.step_cost\n",
        "\n",
        "class Grid:\n",
        "    def __init__(self, height, width):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.grid = [[Cell() for _ in range(width)] for _ in range(height)]\n",
        "\n",
        "    def set_cell(self, row, col, reward=0, cell_type=CellType.EMPTY, step_cost=-1):\n",
        "        self.grid[row][col] = Cell(reward, cell_type, step_cost)\n",
        "\n",
        "    def get_cell(self, row, col):\n",
        "        return self.grid[row][col]\n",
        "\n",
        "    def get_height(self):\n",
        "        return self.height\n",
        "\n",
        "    def get_width(self):\n",
        "        return self.width\n",
        "\n",
        "class PolicyIterationBoltzmann:\n",
        "    def __init__(self, grid, temperature=1.0, cooling_rate=0.995):\n",
        "        self.grid = grid\n",
        "        self.utilities = np.zeros((grid.get_height(), grid.get_width()))\n",
        "        self.policy = np.full((grid.get_height(), grid.get_width()), None)\n",
        "        self.temperature = temperature\n",
        "        self.cooling_rate = cooling_rate\n",
        "        self.actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]  # Right, Left, Down, Up\n",
        "\n",
        "    def run(self):\n",
        "        width = self.grid.get_width()\n",
        "        height = self.grid.get_height()\n",
        "        new_utilities = np.zeros((height, width))\n",
        "\n",
        "        converged = False\n",
        "        while not converged:\n",
        "            converged = True\n",
        "            for i in range(height):\n",
        "                for j in range(width):\n",
        "                    cell = self.grid.get_cell(i, j)\n",
        "                    reward = cell.get_reward()\n",
        "                    if cell.get_cell_type() == CellType.WALL:\n",
        "                        new_utilities[i, j] = 0\n",
        "                        self.policy[i, j] = None\n",
        "                    elif reward != 0:\n",
        "                        new_utilities[i, j] = reward\n",
        "                        self.policy[i, j] = None\n",
        "                    else:\n",
        "                        max_utility = float('-inf')\n",
        "                        best_action = None\n",
        "                        for action_idx, action in enumerate(self.actions):\n",
        "                            utility = 0\n",
        "                            for prob, delta in [(0.8, action), (0.1, (-action[0], action[1])), (0.1, (action[0], -action[1]))]:\n",
        "                                new_x = i + delta[0]\n",
        "                                new_y = j + delta[1]\n",
        "                                if 0 <= new_x < height and 0 <= new_y < width:\n",
        "                                    if self.grid.get_cell(new_x, new_y).get_cell_type() == CellType.WALL:\n",
        "                                        utility += prob * self.utilities[i, j]\n",
        "                                    else:\n",
        "                                        utility += prob * self.utilities[new_x, new_y]\n",
        "                                else:\n",
        "                                    utility += prob * self.utilities[i, j]\n",
        "                            if utility > max_utility:\n",
        "                                max_utility = utility\n",
        "                                best_action = action_idx\n",
        "                        new_utilities[i, j] = cell.get_step_cost() + self.temperature * max_utility\n",
        "                        self.policy[i, j] = best_action\n",
        "\n",
        "                    if abs(new_utilities[i, j] - self.utilities[i, j]) > 0.01:\n",
        "                        converged = False\n",
        "\n",
        "            self.utilities, new_utilities = new_utilities, self.utilities\n",
        "\n",
        "            # Decrease the temperature\n",
        "            self.temperature *= self.cooling_rate\n",
        "\n",
        "        return self.utilities\n",
        "\n",
        "    def get_utilities(self):\n",
        "        return self.utilities\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self.policy\n",
        "\n",
        "    def evaluate_policy(self, episodes=1000):\n",
        "        total_return = 0\n",
        "        for _ in range(episodes):\n",
        "            state = [0, 0]\n",
        "            episode_return = 0\n",
        "            steps = 0\n",
        "            while self.grid.get_cell(state[0], state[1]).get_reward() == 0 and steps < 1000:\n",
        "                action = self.policy[state[0], state[1]]\n",
        "                next_state = self.get_next_state(state, action)\n",
        "                reward = self.grid.get_cell(next_state[0], next_state[1]).get_reward() + self.grid.get_cell(state[0], state[1]).get_step_cost()\n",
        "                episode_return += reward\n",
        "                state = next_state\n",
        "                steps += 1\n",
        "            total_return += episode_return\n",
        "        return total_return / episodes\n",
        "\n",
        "    def get_next_state(self, state, action_idx):\n",
        "        move = self.actions[action_idx]\n",
        "        next_state = [state[0] + move[0], state[1] + move[1]]\n",
        "        if not self.is_valid_location(next_state):\n",
        "            next_state = state\n",
        "        return next_state\n",
        "\n",
        "    def is_valid_location(self, location):\n",
        "        return (0 <= location[0] < self.grid.get_height() and\n",
        "                0 <= location[1] < self.grid.get_width() and\n",
        "                self.grid.get_cell(location[0], location[1]).get_cell_type() != CellType.WALL)\n",
        "\n",
        "    def print_policy(self):\n",
        "        direction_mapping = ['→', '←', '↓', '↑']\n",
        "        policy = [['' for _ in range(self.grid.get_width())] for _ in range(self.grid.get_height())]\n",
        "\n",
        "        for row in range(self.grid.get_height()):\n",
        "            for col in range(self.grid.get_width()):\n",
        "                cell = self.grid.get_cell(row, col)\n",
        "                if cell.get_cell_type() == CellType.WALL:\n",
        "                    policy[row][col] = 'W'  # Wall\n",
        "                elif cell.get_reward() > 0:\n",
        "                    policy[row][col] = 'P'  # Positive reward\n",
        "                elif cell.get_reward() < 0:\n",
        "                    policy[row][col] = 'N'  # Negative reward\n",
        "                else:\n",
        "                    best_action = self.policy[row, col]\n",
        "                    policy[row][col] = direction_mapping[best_action] if best_action is not None else ' '\n",
        "\n",
        "        # Print Policy\n",
        "        print(\"Policy:\")\n",
        "        for row in policy:\n",
        "            print(\" \".join(row))\n",
        "\n",
        "        # Print Utilities using tabulate for prettier printing\n",
        "        utilities_table = [[\"{:.5f}\".format(value) for value in row] for row in self.utilities]\n",
        "        print(\"\\nUtilities:\")\n",
        "        print(tabulate(utilities_table, tablefmt=\"fancy_grid\", numalign=\"center\", stralign=\"center\"))\n",
        "\n",
        "\n",
        "# Example usage with the grid setup\n",
        "def main_policy_iteration_boltzmann(w, h, L, p, r):\n",
        "    grid = Grid(h, w)\n",
        "\n",
        "    for x, y, value in L:\n",
        "        grid.set_cell(h - y - 1, x, reward=value, cell_type=CellType.REWARD if value != 0 else CellType.WALL)\n",
        "\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if grid.get_cell(i, j).get_cell_type() == CellType.EMPTY:\n",
        "                grid.set_cell(i, j, step_cost=r)\n",
        "\n",
        "    pib = PolicyIterationBoltzmann(grid, temperature=1.0, cooling_rate=0.995)\n",
        "\n",
        "    start_time = time.time()\n",
        "    pib.run()\n",
        "    end_time = time.time()\n",
        "\n",
        "    policy_score = pib.evaluate_policy(episodes=1000)\n",
        "    print(\"Policy Score:\", policy_score)\n",
        "    print(f\"Policy Iteration Boltzmann Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "    print(\"\\nPolicy:\")\n",
        "    pib.print_policy()\n",
        "    print(\"=======================================\")\n",
        "\n",
        "# Test each case\n",
        "test_cases = [\n",
        "    # Test case 1\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, -0.04),\n",
        "    # Test case 2\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, 0.04),\n",
        "    # Test case 3\n",
        "    (4, 3, [(1,1,0),(3,2,1),(3,1,-1)], 0.8, -1),\n",
        "    # Test case 4\n",
        "    (12, 4, [(1,0,-100),(2,0,-100),(3,0,-100),(4,0,-100),(5,0,-100),(6,0,-100),(7,0,-100),(8,0,-100),(9,0,-100),(10,0,-100),(11,0,1)], 1, -1),\n",
        "    # Test case 5\n",
        "    (12, 6, [(1,0,-100),(2,0,-100),(3,0,-100),(4,0,-100),(5,0,-100),(6,0,-100),(7,0,-100),(8,0,-100),(9,0,-100),(10,0,-100),(11,0,1)], 0.9, -1),\n",
        "    # Test case 6\n",
        "    (5, 5, [(4,0,-10),(0,4,-10),(1,1,1),(3,3,2)], 0.9, -0.5),\n",
        "    # Test case 7\n",
        "    (5, 5, [(2,2,-2),(4,4,-1),(1,1,1),(3,3,2)], 0.9, -0.25),\n",
        "    # Test case 8\n",
        "    (7, 7, [(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.5),\n",
        "    # Test case 9\n",
        "    (7, 7, [(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.5),\n",
        "    # Test case 10\n",
        "    (7, 7, [(3,1,0),(3,5,0),(1,1,-4),(1,5,-6),(5,1,1),(5,5,4)], 0.8, -0.25)\n",
        "]\n",
        "\n",
        "for i, (w, h, L, p, r) in enumerate(test_cases, start=1):\n",
        "    print(f\"\\nRunning test case {i}\")\n",
        "    main_policy_iteration_boltzmann(w, h, L, p, r)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------\n",
        "#Model-free RL (Q-Learning)\n",
        "#----------------------\n",
        "import numpy as np\n",
        "import random\n",
        "from tabulate import tabulate\n",
        "\n",
        "class GridGameQLearning:\n",
        "    def __init__(self, rows, cols, rewards, success_probabilities, costs, walls, gamma=0.9):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.rewards = rewards\n",
        "        self.success_probabilities = success_probabilities\n",
        "        self.costs = costs\n",
        "        self.walls = walls\n",
        "        self.gamma = gamma\n",
        "        self.q_table = np.zeros((rows, cols, 4))\n",
        "        self.policy = np.zeros((rows, cols), dtype=int)\n",
        "        self.actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "\n",
        "    def is_valid_location(self, location):\n",
        "        return (0 <= location[0] < self.rows and\n",
        "                0 <= location[1] < self.cols and\n",
        "                location not in self.walls)\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "        move = self.actions[action]\n",
        "        next_state = [state[0] + move[0], state[1] + move[1]]\n",
        "\n",
        "        # Check if the move results in hitting a wall\n",
        "        if not self.is_valid_location(next_state):\n",
        "            next_state = state\n",
        "        else:\n",
        "            # Determine if the move is successful based on probability\n",
        "            success_prob = self.success_probabilities.get(tuple(move), 0)\n",
        "            if random.uniform(0, 1) > success_prob:\n",
        "                # Move failed, attempt to move right or left in the same direction\n",
        "                if action == 0:  # Right\n",
        "                    right_move = self.actions[2]  # Down\n",
        "                    left_move = self.actions[3]   # Up\n",
        "                elif action == 1:  # Left\n",
        "                    right_move = self.actions[3]  # Up\n",
        "                    left_move = self.actions[2]   # Down\n",
        "                elif action == 2:  # Down\n",
        "                    right_move = self.actions[1]  # Left\n",
        "                    left_move = self.actions[0]   # Right\n",
        "                elif action == 3:  # Up\n",
        "                    right_move = self.actions[0]  # Right\n",
        "                    left_move = self.actions[1]   # Left\n",
        "\n",
        "                # Attempt right move\n",
        "                if self.is_valid_location([state[0] + right_move[0], state[1] + right_move[1]]):\n",
        "                    next_state = [state[0] + right_move[0], state[1] + right_move[1]]\n",
        "                # If right move is not possible, attempt left move\n",
        "                elif self.is_valid_location([state[0] + left_move[0], state[1] + left_move[1]]):\n",
        "                    next_state = [state[0] + left_move[0], state[1] + left_move[1]]\n",
        "                else:\n",
        "                    next_state = state\n",
        "\n",
        "        return next_state\n",
        "\n",
        "    def choose_action(self, state, epsilon):\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.choice(range(4))\n",
        "        else:\n",
        "            row, col = state\n",
        "            return np.argmax(self.q_table[row, col])\n",
        "\n",
        "    def q_learning(self, num_episodes=1000, alpha=0.1, epsilon=0.1):\n",
        "        for episode in range(num_episodes):\n",
        "            state = [random.randint(0, self.rows - 1), random.randint(0, self.cols - 1)]\n",
        "            while self.rewards[state[0]][state[1]] == 0:\n",
        "                action = self.choose_action(state, epsilon)\n",
        "                next_state = self.get_next_state(state, action)\n",
        "\n",
        "                # Calculate reward based on next state\n",
        "                reward = self.rewards[next_state[0]][next_state[1]] + self.costs[state[0]][state[1]]\n",
        "\n",
        "                row, col = state\n",
        "                next_row, next_col = next_state\n",
        "\n",
        "                # Adjust reward based on success probability and step cost\n",
        "                success_prob = self.success_probabilities.get(tuple(self.actions[action]), 0)\n",
        "                effective_reward = reward + (1 - success_prob) * self.costs[state[0]][state[1]]\n",
        "\n",
        "                self.q_table[row, col, action] += alpha * (\n",
        "                    effective_reward + self.gamma * np.max(self.q_table[next_row, next_col]) - self.q_table[row, col, action])\n",
        "\n",
        "                state = next_state\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                self.policy[row][col] = np.argmax(self.q_table[row, col])\n",
        "\n",
        "    def evaluate_policy(self, episodes=10000, epsilon=0.1):\n",
        "        total_return = 0\n",
        "        for _ in range(episodes):\n",
        "            state = [0, 0]\n",
        "            episode_return = 0\n",
        "            while self.rewards[state[0]][state[1]] == 0:\n",
        "                if random.uniform(0, 1) < epsilon:\n",
        "                    action = random.choice(range(4))\n",
        "                else:\n",
        "                    action = self.policy[state[0], state[1]]\n",
        "                next_state = self.get_next_state(state, action)\n",
        "                reward = self.rewards[state[0]][state[1]] + self.costs[state[0]][state[1]]\n",
        "                episode_return += reward\n",
        "                state = next_state\n",
        "            total_return += episode_return\n",
        "        return total_return / episodes\n",
        "\n",
        "    def print_policy(self):\n",
        "        direction_mapping = ['→', '←', '↓', '↑']\n",
        "        policy = [[None for _ in range(self.cols)] for _ in range(self.rows)]\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                if [row, col] in self.walls:\n",
        "                    policy[row][col] = 'W'  # Wall\n",
        "                elif self.rewards[row][col] > 0:\n",
        "                    policy[row][col] = 'P'  # Positive reward\n",
        "                elif self.rewards[row][col] < 0:\n",
        "                    policy[row][col] = 'N'  # Negative reward\n",
        "                else:\n",
        "                    best_action = self.policy[row, col]\n",
        "                    policy[row][col] = direction_mapping[best_action]\n",
        "        for row in policy:\n",
        "            print(\" \".join(row))\n",
        "\n",
        "    def print_utilities(self):\n",
        "        utilities_table = [[\"{:.5f}\".format(np.max(self.q_table[row, col])) for col in range(self.cols)] for row in range(self.rows)]\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols):\n",
        "                if [row, col] in self.walls:\n",
        "                    utilities_table[row][col] = 'W'  # Wall\n",
        "                elif self.rewards[row][col] > 0:\n",
        "                    utilities_table[row][col] = {self.rewards[row][col]}  # Positive reward\n",
        "                elif self.rewards[row][col] < 0:\n",
        "                    utilities_table[row][col] = {self.rewards[row][col]}  # Negative reward\n",
        "        headers = [f\"Col {col}\" for col in range(self.cols)]\n",
        "        print(\"\\nUtilities:\")\n",
        "        print(tabulate(utilities_table, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "def main_q_learning_multiple():\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"w\": 4,\n",
        "            \"h\": 3,\n",
        "            \"L\": [(1, 1, 0), (3, 2, 1), (3, 1, -1)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": -0.04\n",
        "        },\n",
        "        {\n",
        "            \"w\": 4,\n",
        "            \"h\": 3,\n",
        "            \"L\": [(1, 1, 0), (3, 2, 1), (3, 1, -1)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": 0.04\n",
        "        },\n",
        "        {\n",
        "            \"w\": 4,\n",
        "            \"h\": 3,\n",
        "            \"L\": [(1, 1, 0), (3, 2, 1), (3, 1, -1)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": -1\n",
        "        },\n",
        "        {\n",
        "            \"w\": 12,\n",
        "            \"h\": 4,\n",
        "            \"L\": [(1, 0, -100), (2, 0, -100), (3, 0, -100), (4, 0, -100), (5, 0, -100), (6, 0, -100), (7, 0, -100), (8, 0, -100), (9, 0, -100), (10, 0, -100), (11, 0, 1)],\n",
        "            \"p\": 1,\n",
        "            \"r\": -1\n",
        "        },\n",
        "        {\n",
        "            \"w\": 12,\n",
        "            \"h\": 6,\n",
        "            \"L\": [(1, 0, -100), (2, 0, -100), (3, 0, -100), (4, 0, -100), (5, 0, -100), (6, 0, -100), (7, 0, -100), (8, 0, -100), (9, 0, -100), (10, 0, -100), (11, 0, 1)],\n",
        "            \"p\": 0.9,\n",
        "            \"r\": -1\n",
        "        },\n",
        "        {\n",
        "            \"w\": 5,\n",
        "            \"h\": 5,\n",
        "            \"L\": [(4, 0, -10), (0, 4, -10), (1, 1, 1), (3, 3, 2)],\n",
        "            \"p\": 0.9,\n",
        "            \"r\": -0.5\n",
        "        },\n",
        "        {\n",
        "            \"w\": 5,\n",
        "            \"h\": 5,\n",
        "            \"L\": [(2, 2, -2), (4, 4, -1), (1, 1, 1), (3, 3, 2)],\n",
        "            \"p\": 0.9,\n",
        "            \"r\": -0.25\n",
        "        },\n",
        "        {\n",
        "            \"w\": 7,\n",
        "            \"h\": 7,\n",
        "            \"L\": [(1, 1, -4), (1, 5, -6), (5, 1, 1), (5, 5, 4)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": -0.5\n",
        "        },\n",
        "        {\n",
        "            \"w\": 7,\n",
        "            \"h\": 7,\n",
        "            \"L\": [(1, 1, -4), (1, 5, -6), (5, 1, 1), (5, 5, 4)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": -0.5\n",
        "        },\n",
        "        {\n",
        "            \"w\": 7,\n",
        "            \"h\": 7,\n",
        "            \"L\": [(3, 1, 0), (3, 5, 0), (1, 1, -4), (1, 5, -6), (5, 1, 1), (5, 5, 4)],\n",
        "            \"p\": 0.8,\n",
        "            \"r\": -0.25\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for idx, test_case in enumerate(test_cases):\n",
        "        w = test_case[\"w\"]\n",
        "        h = test_case[\"h\"]\n",
        "        L = test_case[\"L\"]\n",
        "        p = test_case[\"p\"]\n",
        "        r = test_case[\"r\"]\n",
        "\n",
        "        rewards = [[0 for _ in range(w)] for _ in range(h)]\n",
        "        costs = [[r for _ in range(w)] for _ in range(h)]\n",
        "        walls = []\n",
        "\n",
        "        for x, y, value in L:\n",
        "            if value == 0:\n",
        "                walls.append([h - y - 1, x])  # Convert (x, y) to (row, col) with (0,0) at lower-left\n",
        "            else:\n",
        "                rewards[h - y - 1][x] = value\n",
        "\n",
        "        success_probabilities = {\n",
        "            (0, 1): p,\n",
        "            (0, -1): p,\n",
        "            (1, 0): p,\n",
        "            (-1, 0): p\n",
        "        }\n",
        "\n",
        "        print(f\"Running test case {idx + 1}...\")\n",
        "        game_q_learning = GridGameQLearning(h, w, rewards, success_probabilities, costs, walls)\n",
        "        start_time = time.time()\n",
        "        game_q_learning.q_learning(num_episodes=30000, alpha=0.1, epsilon=0.1)\n",
        "        end_time = time.time()\n",
        "        policy_score = game_q_learning.evaluate_policy(episodes=1000, epsilon=0.1)\n",
        "        print(f\"Policy Score for test case {idx + 1}: {policy_score}\")\n",
        "        print(f\"Q-learning Time for test case {idx + 1}: {end_time - start_time:.4f} seconds\")\n",
        "        print(\"\\nPolicy for test case {idx + 1}:\")\n",
        "        game_q_learning.print_policy()\n",
        "        print(\"\\nUtilities for test case {idx + 1}:\")\n",
        "        game_q_learning.print_utilities()\n",
        "        print(\"-----------------------------------\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_q_learning_multiple()"
      ],
      "metadata": {
        "id": "Q_GrUQE0FYDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2dc7e0-8bae-45f9-b575-f061a25db310",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test case 1...\n",
            "Policy Score for test case 1: -0.19200000000000048\n",
            "Q-learning Time for test case 1: 2.4034 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "↑ ← ← ←\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+---------+---------+---------+----------+\n",
            "|   Col 0 | Col 1   |   Col 2 | Col 3    |\n",
            "+=========+=========+=========+==========+\n",
            "| 0.51105 | 0.67108 | 0.84133 | {1}      |\n",
            "+---------+---------+---------+----------+\n",
            "| 0.39674 | W       | 0.28232 | {-1}     |\n",
            "+---------+---------+---------+----------+\n",
            "| 0.24967 | 0.16743 | 0.1092  | -0.04339 |\n",
            "+---------+---------+---------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 2...\n",
            "Policy Score for test case 2: 2.66228\n",
            "Q-learning Time for test case 2: 5.7529 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ ↑ → P\n",
            "↑ W ← N\n",
            "↑ ← ← →\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+---------+---------+---------+---------+\n",
            "|   Col 0 | Col 1   |   Col 2 | Col 3   |\n",
            "+=========+=========+=========+=========+\n",
            "| 0.80014 | 0.79198 | 0.81494 | {1}     |\n",
            "+---------+---------+---------+---------+\n",
            "| 0.77346 | W       | 0.48    | {-1}    |\n",
            "+---------+---------+---------+---------+\n",
            "| 0.73063 | 0.69998 | 0.63446 | 0.48000 |\n",
            "+---------+---------+---------+---------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 3...\n",
            "Policy Score for test case 3: -4.798\n",
            "Q-learning Time for test case 3: 1.6329 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → P\n",
            "↑ W ↑ N\n",
            "→ → ↑ ↑\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+----------+\n",
            "|    Col 0 | Col 1    |    Col 2 | Col 3    |\n",
            "+==========+==========+==========+==========+\n",
            "| -4.10726 | -2.36826 | -0.62789 | {1}      |\n",
            "+----------+----------+----------+----------+\n",
            "| -4.92726 | W        | -2.15424 | {-1}     |\n",
            "+----------+----------+----------+----------+\n",
            "| -5.02646 | -4.20881 | -3.27953 | -2.35245 |\n",
            "+----------+----------+----------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 4...\n",
            "Policy Score for test case 4: -15.151\n",
            "Q-learning Time for test case 4: 3.2391 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ N N N N N N N N N N P\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|    Col 0 | Col 1    | Col 2    | Col 3    | Col 4    | Col 5    | Col 6    | Col 7    | Col 8    | Col 9    | Col 10   | Col 11   |\n",
            "+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+\n",
            "| -7.45813 | -7.17570 | -6.86189 | -6.51322 | -6.12580 | -5.69533 | -5.21703 | -4.68559 | -4.09510 | -3.43900 | -2.71000 | -1.90000 |\n",
            "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| -7.1757  | -6.86189 | -6.51322 | -6.12580 | -5.69533 | -5.21703 | -4.68559 | -4.09510 | -3.43900 | -2.71000 | -1.90000 | -1.00000 |\n",
            "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| -6.86189 | -6.51322 | -6.12580 | -5.69533 | -5.21703 | -4.68559 | -4.09510 | -3.43900 | -2.71000 | -1.90000 | -1.00000 | 0.00000  |\n",
            "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| -7.1757  | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {1}      |\n",
            "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 5...\n",
            "Policy Score for test case 5: -19.16\n",
            "Q-learning Time for test case 5: 5.8385 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "→ → → → → → → → → → → ↓\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↓\n",
            "← N N N N N N N N N N P\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|     Col 0 | Col 1    | Col 2    | Col 3    | Col 4    | Col 5    | Col 6    | Col 7    | Col 8    | Col 9    | Col 10   | Col 11   |\n",
            "+===========+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+\n",
            "|  -8.98905 | -8.76479 | -8.51449 | -8.22891 | -7.92053 | -7.58431 | -7.21035 | -6.79205 | -6.34773 | -5.84276 | -5.28188 | -4.68089 |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|  -8.78055 | -8.50840 | -8.22817 | -7.92621 | -7.57433 | -7.18378 | -6.74575 | -6.27169 | -5.76772 | -5.24225 | -4.68633 | -3.99259 |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|  -8.62385 | -8.33962 | -8.01428 | -7.64873 | -7.23334 | -6.76913 | -6.28024 | -5.76692 | -5.23814 | -4.64356 | -4.01464 | -3.17545 |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|  -8.66404 | -8.32848 | -7.99476 | -7.54724 | -7.12389 | -6.56266 | -6.04541 | -5.44492 | -4.81488 | -4.04731 | -3.13386 | -1.82416 |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|  -8.91463 | -8.64319 | -8.35206 | -7.95845 | -7.48939 | -7.05431 | -6.57035 | -5.97425 | -5.41009 | -4.56145 | -3.77594 | -0.28210 |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| -11       | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {-100}   | {1}      |\n",
            "+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 6...\n",
            "Policy Score for test case 6: 0.0\n",
            "Q-learning Time for test case 6: 1.0152 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "N → → ↓ ↓\n",
            "→ → → P ←\n",
            "↓ ↓ ↑ ↑ ↑\n",
            "→ P ← ↑ ↑\n",
            "→ ↑ ← ← N\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+----------+----------+\n",
            "| Col 0    | Col 1    |    Col 2 | Col 3    | Col 4    |\n",
            "+==========+==========+==========+==========+==========+\n",
            "| {-10}    | -0.03905 |  0.55233 | 1.10715  | 0.56064  |\n",
            "+----------+----------+----------+----------+----------+\n",
            "| -0.08304 | 0.63554  |  1.25111 | {2}      | 1.21958  |\n",
            "+----------+----------+----------+----------+----------+\n",
            "| -0.27624 | 0.37027  |  0.61426 | 1.27115  | 0.57545  |\n",
            "+----------+----------+----------+----------+----------+\n",
            "| 0.36337  | {1}      |  0.396   | 0.42135  | -0.03161 |\n",
            "+----------+----------+----------+----------+----------+\n",
            "| -0.28051 | 0.39840  | -0.26775 | -0.65854 | {-10}    |\n",
            "+----------+----------+----------+----------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 7...\n",
            "Policy Score for test case 7: -1.27725\n",
            "Q-learning Time for test case 7: 1.2237 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → ↓ N\n",
            "→ → ↑ P ←\n",
            "↓ ↓ N ↑ ←\n",
            "→ P → ↑ ↑\n",
            "→ ↑ → ↑ ↑\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+---------+---------+---------+---------+---------+\n",
            "|   Col 0 | Col 1   | Col 2   | Col 3   | Col 4   |\n",
            "+=========+=========+=========+=========+=========+\n",
            "| 0.2945  | 0.69235 | 1.09236 | 1.64026 | {-1}    |\n",
            "+---------+---------+---------+---------+---------+\n",
            "| 0.14705 | 0.46081 | 0.79357 | {2}     | 1.65741 |\n",
            "+---------+---------+---------+---------+---------+\n",
            "| 0.31374 | 0.54008 | {-2}    | 1.72003 | 1.23820 |\n",
            "+---------+---------+---------+---------+---------+\n",
            "| 0.66549 | {1}     | 0.61412 | 1.22494 | 0.81343 |\n",
            "+---------+---------+---------+---------+---------+\n",
            "| 0.31937 | 0.63700 | 0.36294 | 0.78162 | 0.43764 |\n",
            "+---------+---------+---------+---------+---------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 8...\n",
            "Policy Score for test case 8: -3.5255\n",
            "Q-learning Time for test case 8: 2.5138 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → → → ↓ ←\n",
            "↓ N → → → P ←\n",
            "→ → → ↑ ↑ ↑ ←\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑\n",
            "↑ N ↑ ↑ ↑ P ←\n",
            "→ → → → → ↑ ↑\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "|    Col 0 | Col 1    |    Col 2 |    Col 3 |    Col 4 | Col 5   |    Col 6 |\n",
            "+==========+==========+==========+==========+==========+=========+==========+\n",
            "| -2.13614 | -1.30875 |  0.44264 |  1.20713 |  2.1175  | 3.22564 |  2.13555 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -3.48695 | {-6}     |  0.40783 |  1.7972  |  2.90043 | {4}     |  3.08626 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -1.44131 | -0.69615 |  0.11028 |  1.11887 |  1.99354 | 3.34280 |  2.17586 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -1.8575  | -1.21588 | -0.57948 |  0.43072 |  1.29407 | 2.17415 |  1.23362 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -2.22987 | -1.69482 | -1.08983 | -0.22764 |  0.4972  | 0.99697 |  0.48304 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -3.0248  | {-4}     | -1.51156 | -0.803   |  0.02823 | {1}     |  0.26996 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -3.01295 | -2.25913 | -1.64415 | -1.11689 | -0.57011 | 0.08954 | -0.41154 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 9...\n",
            "Policy Score for test case 9: -3.395\n",
            "Q-learning Time for test case 9: 2.3819 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → → → ↓ ←\n",
            "↓ N → → → P ←\n",
            "→ → ↑ ↑ ↑ ↑ ←\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑\n",
            "↑ N ↑ ↑ → P ←\n",
            "→ → → → → ↑ ↑\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "|    Col 0 | Col 1    |    Col 2 |    Col 3 |    Col 4 | Col 5   |    Col 6 |\n",
            "+==========+==========+==========+==========+==========+=========+==========+\n",
            "| -2.07596 | -0.75260 |  0.41924 |  1.29754 |  2.17216 | 3.26129 |  2.19653 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -2.34369 | {-6}     |  0.62701 |  1.81963 |  2.79265 | {4}     |  2.87284 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -1.32708 | -0.69271 |  0.03043 |  0.94932 |  1.99686 | 3.13433 |  2.15153 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -1.8929  | -1.21360 | -0.51173 |  0.33274 |  1.17872 | 2.00215 |  1.20507 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -2.32916 | -1.65748 | -1.01264 | -0.29945 |  0.33718 | 0.93067 |  0.35207 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -3.0264  | {-4}     | -1.47576 | -0.77797 |  0.14585 | {1}     |  0.27463 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "| -2.96176 | -2.48304 | -1.69864 | -1.12935 | -0.51522 | 0.04620 | -0.36952 |\n",
            "+----------+----------+----------+----------+----------+---------+----------+\n",
            "-----------------------------------\n",
            "\n",
            "Running test case 10...\n",
            "Policy Score for test case 10: -1.839\n",
            "Q-learning Time for test case 10: 3.3014 seconds\n",
            "\n",
            "Policy for test case {idx + 1}:\n",
            "→ → → → → ↓ ↓\n",
            "↓ N ↓ W → P ←\n",
            "→ → → → ↑ ↑ ↑\n",
            "↑ ↑ ↑ ↑ ↑ ↑ ↑\n",
            "↑ ↑ ↑ → ↑ ↑ ↑\n",
            "↑ N ↑ W ↑ P ↑\n",
            "→ → → → ↑ ↑ ↑\n",
            "\n",
            "Utilities for test case {idx + 1}:\n",
            "\n",
            "Utilities:\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "|    Col 0 | Col 1    |    Col 2 | Col 3   |   Col 4 | Col 5   |   Col 6 |\n",
            "+==========+==========+==========+=========+=========+=========+=========+\n",
            "| -1.79366 | -0.70307 |  1.17441 | 2.05523 | 2.77015 | 3.47423 | 2.69474 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "| -1.87221 | {-6}     | -1.26864 | W       | 3.556   | {4}     | 3.495   |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "|  0.23527 | 0.86692  |  1.37387 | 2.00617 | 2.75269 | 3.29677 | 2.67083 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "| -0.14033 | 0.43167  |  0.97265 | 1.48084 | 2.10565 | 2.41984 | 2.09538 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "| -0.33172 | 0.10575  |  0.59858 | 1.12413 | 1.59823 | 1.91468 | 1.55007 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "| -1.50298 | {-4}     |  0.14016 | W       | 0.9932  | {1}     | 1.03731 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "| -1.71969 | -1.37611 | -0.23482 | 0.11662 | 0.52344 | 0.65812 | 0.55053 |\n",
            "+----------+----------+----------+---------+---------+---------+---------+\n",
            "-----------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def is_number(value):\n",
        "    \"\"\"Check if the value is a number.\"\"\"\n",
        "    try:\n",
        "        float(value)\n",
        "        return True\n",
        "    except (ValueError, TypeError):\n",
        "        return False\n",
        "\n",
        "def average_distance(matrix1, matrix2):\n",
        "    \"\"\"Calculate the average distance between two matrices, ignoring non-numeric entries.\"\"\"\n",
        "    if len(matrix1) != len(matrix2) or any(len(row1) != len(row2) for row1, row2 in zip(matrix1, matrix2)):\n",
        "        raise ValueError(\"Matrices must have the same dimensions\")\n",
        "\n",
        "    total_distance = 0\n",
        "    count = 0\n",
        "\n",
        "    for row1, row2 in zip(matrix1, matrix2):\n",
        "        for val1, val2 in zip(row1, row2):\n",
        "            if is_number(val1) and is_number(val2):\n",
        "                total_distance += abs(float(val1) - float(val2))\n",
        "                count += 1\n",
        "\n",
        "    if count == 0:\n",
        "        return 0  # Avoid division by zero if no numeric entries are found\n",
        "    return total_distance / count\n",
        "\n",
        "\n",
        "# Example matrices\n",
        "matrix1 = [\n",
        "    [0.5144, 0.66944, 0.87395, 1],\n",
        "    [0.40442, 0, 0.14432, -1],\n",
        "    [0.30061, 0.19045, 0.15729, -0.1208]\n",
        "]\n",
        "\n",
        "matrix2 = [\n",
        "    [0.5144, 0.66944, 0.87395, 1],\n",
        "    [0.40442, 0, 0.14432, -1],\n",
        "    [0.30061, 0.19045, 0.15729, -0.1208]\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the average distance\n",
        "avg_distance = average_distance(matrix1, matrix2)\n",
        "print(\"Average Distance:\", avg_distance)\n",
        "\n",
        "# Function to calculate absolute difference or return '---' if any element is '--------------' or None\n",
        "def calculate_difference(a, b):\n",
        "    if a == '--------------' or b == '--------------' or a is None or b is None:\n",
        "        return '---'\n",
        "    else:\n",
        "        return abs(a - b)\n",
        "\n",
        "# Initialize a list to store results\n",
        "differences = []\n",
        "\n",
        "# Iterate through each element in matrix1 and matrix2\n",
        "for i in range(len(matrix1)):\n",
        "    for j in range(len(matrix1[i])):\n",
        "        diff = calculate_difference(matrix1[i][j], matrix2[i][j])\n",
        "        differences.append((f\"({i},{j})\", diff))\n",
        "\n",
        "# Print the results\n",
        "index_values = \" \".join([str(index) for index, diff in differences])\n",
        "diff_values = \" \".join([str(diff) for index, diff in differences])\n",
        "\n",
        "# Print to console for copying\n",
        "print(\"Index values:\")\n",
        "print(index_values)\n",
        "print(\"\\nDiff values:\")\n",
        "print(diff_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJuZXsc3xqC",
        "outputId": "0d070ad2-3c6c-46dd-e422-70a2ea06abf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Distance: 0.0\n",
            "Index values:\n",
            "(0,0) (0,1) (0,2) (0,3) (1,0) (1,1) (1,2) (1,3) (2,0) (2,1) (2,2) (2,3)\n",
            "\n",
            "Diff values:\n",
            "0.0 0.0 0.0 0 0.0 0 0.0 0 0.0 0.0 0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erZW7ypV3xni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjvMmsZn3xlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26whSwIR3xih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRcGeCem3xfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJjgeq8E3xct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9G1X5zz3xZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cs0l5fbJ3xWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4geVFna3xSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kX4Gq3PD3xJS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}